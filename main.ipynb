{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a54a42b-79f9-4154-84d7-248efae71c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile main.py\n",
    "\n",
    "# This file starts the training\n",
    "# test JL -> py\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Resize\n",
    "\n",
    "from torch.cuda import empty_cache\n",
    "from torch.utils.data import DataLoader # Dataset                                                                                                                                                                    \n",
    "from torch.utils.data.sampler import SubsetRandomSampler # RandomSampling\n",
    "# from torchvision import transforms\n",
    "\n",
    "import config as c\n",
    "from train import train\n",
    "\n",
    "#from utils import load_datasets, make_dataloaders\n",
    "from data_loader import CowObjectsDataset, CustToTensor, train_valid_split\n",
    "\n",
    "empty_cache() # free up memory for cuda\n",
    "\n",
    "# torchivsion inputs are 3x227x227, mnist_resnet 1x227...\n",
    "# 0.1307, 0.3081 = mean, std dev mnist\n",
    "mnist_pre = Compose([Resize((c.img_size[0], c.img_size[0])),ToTensor(),Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "\n",
    "if c.mnist:\n",
    "    mnist_train = MNIST(root='./data', train=True, download=True, transform=mnist_pre)\n",
    "    mnist_test = MNIST(root='./data', train=False, download=True, transform=mnist_pre)\n",
    "    \n",
    "    toy_sampler = SubsetRandomSampler(range(100))\n",
    "    \n",
    "    if c.test_run:\n",
    "        train_loader = DataLoader(mnist_train,batch_size = c.batch_size,pin_memory=True,\n",
    "                                  shuffle=False,sampler=toy_sampler)\n",
    "        valid_loader = DataLoader(mnist_test,batch_size = c.batch_size,pin_memory=True,\n",
    "                                  shuffle=False,sampler=toy_sampler)\n",
    "    else:\n",
    "        train_loader = DataLoader(mnist_train,batch_size = c.batch_size,pin_memory=True,\n",
    "                              shuffle=True)\n",
    "        valid_loader = DataLoader(mnist_test,batch_size = c.batch_size,pin_memory=True,\n",
    "                              shuffle=True)\n",
    "    \n",
    "    model = train(train_loader,valid_loader)\n",
    "else:\n",
    "    # instantiate class\n",
    "    transformed_dataset = CowObjectsDataset(root_dir=c.proj_dir,transform = CustToTensor(),\n",
    "                                            convert_to_points=True,generate_density=True)\n",
    "    \n",
    "    # create test train split\n",
    "    train_indices, valid_indices = train_valid_split(dataset = transformed_dataset, train_percent = 70,annotations_only = c.annotations_only)\n",
    "    \n",
    "    # TODO: code to save this file (train and valid indices)\n",
    "    \n",
    "    # Creating data samplers and loaders:\n",
    "    # only train part for dev purposes \n",
    "    \n",
    "    if not c.annotations_only:\n",
    "        train_sampler = SubsetRandomSampler(train_indices[:round(c.data_prop*len(train_indices))])\n",
    "        valid_sampler = SubsetRandomSampler(valid_indices[:round(c.data_prop*len(valid_indices))])\n",
    "    \n",
    "    if c.annotations_only:\n",
    "        train_sampler = SubsetRandomSampler(train_indices)\n",
    "        valid_sampler = SubsetRandomSampler(valid_indices)\n",
    "    \n",
    "    if c.verbose:\n",
    "        print(\"Training using {} train samples and {} validation samples...\".format(len(train_sampler)*c.batch_size,len(valid_sampler)*c.batch_size))\n",
    "    \n",
    "    train_loader = DataLoader(transformed_dataset, batch_size=c.batch_size,shuffle=False, \n",
    "                            num_workers=0,collate_fn=transformed_dataset.custom_collate_density,\n",
    "                            pin_memory=True,sampler=train_sampler)\n",
    "    \n",
    "    valid_loader = DataLoader(transformed_dataset, batch_size=c.batch_size,shuffle=False, \n",
    "                            num_workers=0,collate_fn=transformed_dataset.custom_collate_density,\n",
    "                            pin_memory=True,sampler=valid_sampler)\n",
    "    \n",
    "    model = train(train_loader,valid_loader) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279b9864-0e0f-4d27-8f7b-ed5ed85558e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db822ddc-8555-4b5c-bb94-ebc01609122f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
